import { NextRequest, NextResponse } from 'next/server'
import {
  openai,
  AI_CONFIG,
  UNDERSTANDING_PROMPT,
  getExtractionPrompt,
} from '@/lib/ai/openai'
import {
  AI_TOOLS,
  validateEventsArgs,
  validateUrgentMessageArgs,
  validateHighlightArgs,
} from '@/lib/ai/tools'
import { logAICost } from '@/lib/ai/cost-tracker'
import { incrementAiUsage, validateMessageLength } from '@/lib/ai/rate-limiter'
import { aiLogger } from '@/lib/ai/logger'

// Force dynamic rendering
export const dynamic = 'force-dynamic'
export const revalidate = 0

// Types for request/response
interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

interface AIAssistantRequest {
  messages: ChatMessage[]
  action?: 'initial' | 'select_type' | 'extract_data' | 'understand_message'
  context?: string // Optional context from understanding round
}

export async function POST(req: NextRequest) {
  try {
    const body: AIAssistantRequest = await req.json()
    const { messages, action = 'extract_data', context } = body

    // Handle initial greeting (no rate limit check - doesn't use GPT)
    if (action === 'initial') {
      aiLogger.logInitial()
      return NextResponse.json({
        success: true,
        message: `×©×œ×•×! ğŸ‘‹

××” ×ª×¨×¦×” ×œ×”×•×¡×™×£ ×œ××¢×¨×›×ª?

1ï¸âƒ£ **××™×¨×•×¢** - ××™×¨×•×¢ ×‘×œ×•×— ×”×©× ×” ×©×œ ×‘×™×ª ×”×¡×¤×¨
2ï¸âƒ£ **×”×•×“×¢×” ×“×—×•×¤×”** - ×”×•×“×¢×” ×©×ª×•×¦×’ ×‘×‘×× ×¨ ×‘×“×£ ×”×‘×™×ª
3ï¸âƒ£ **×”×“×’×©×”** - ×”×™×©×’/×¤×¨×¡/××™×¨×•×¢ ××™×•×—×“ ×œ×§×¨×•×¡×œ×ª ×“×£ ×”×‘×™×ª

×‘×—×¨ ××¤×©×¨×•×ª ×•××¡×‘×™×¨ ×œ×š ××” ×¦×¨×™×š ×œ××œ×.

ğŸ’¡ ××’×‘×œ×” ×™×•××™×ª: 20 ×©×™××•×©×™× ×‘×™×•× | ××§×¡×™××•× 1500 ×ª×•×•×™× ×œ×”×•×“×¢×”`,
      })
    }

    // Check rate limit for all GPT requests
    const rateLimitResult = await incrementAiUsage()

    // Log rate limit check
    aiLogger.logRateLimit({
      usageCount: rateLimitResult.stats.currentCount,
      dailyLimit: rateLimitResult.stats.dailyLimit,
      rateLimitReached: rateLimitResult.stats.limitReached,
    })

    if (!rateLimitResult.success || rateLimitResult.stats.limitReached) {
      console.warn('[AI Assistant] Rate limit reached:', rateLimitResult.stats)
      return NextResponse.json({
        success: false,
        error: `×”×’×¢×ª ×œ××’×‘×œ×” ×”×™×•××™×ª ×©×œ 20 ×©×™××•×©×™× ğŸ˜”

× ×¡×” ×©×•×‘ ××—×¨ ××• ×¦×•×¨ ×§×©×¨ ×¢× ×”×× ×”×œ.

×©×™××•×©×™× ×”×™×•×: ${rateLimitResult.stats.currentCount}/${rateLimitResult.stats.dailyLimit}`,
        rateLimitReached: true,
        stats: rateLimitResult.stats,
      })
    }

    // Validate message length (400 chars max)
    const lastUserMessage = messages[messages.length - 1]?.content || ''
    const lengthValidation = validateMessageLength(lastUserMessage)

    if (!lengthValidation.valid) {
      return NextResponse.json({
        success: false,
        error: `×”×”×•×“×¢×” ××¨×•×›×” ××“×™ ğŸ“

××§×¡×™××•×: ${lengthValidation.maxLength} ×ª×•×•×™×
×”×”×•×“×¢×” ×©×œ×š: ${lengthValidation.length} ×ª×•×•×™×

× ×¡×” ×œ×§×¦×¨ ××ª ×”×”×•×“×¢×”.`,
        messageTooLong: true,
      })
    }

    // Handle type selection
    if (action === 'select_type') {
      const lastMessage = messages[messages.length - 1]
      const userInput = lastMessage.content.toLowerCase()

      if (userInput.includes('××™×¨×•×¢') || userInput === '1') {
        return NextResponse.json({
          success: true,
          message: `××¢×•×œ×”! ×‘×•× × ×™×¦×•×¨ ××™×¨×•×¢ ×—×“×© ğŸ“…

**×ª××¨ ××ª ×”××™×¨×•×¢ ×‘××©×¤×˜ ××—×“**, ×›×•×œ×œ:
â€¢ ×©× ×”××™×¨×•×¢
â€¢ ×ª××¨×™×š (×œ×“×•×’××”: 15 ×‘××¨×¥ ××• 15/03/2025)
â€¢ ×©×¢×” (×œ×“×•×’××”: 17:00 ××• 5 ××—×”×´×¦) - ××•×¤×¦×™×•× ×œ×™
â€¢ ××™×§×•× - ××•×¤×¦×™×•× ×œ×™

**×“×•×’××”:**
"××¡×™×‘×ª ×¤×•×¨×™× ×‘-15/03/2025 ×‘×©×¢×” 17:00 ×‘×’×Ÿ ×”×™×œ×“×™×"

××•:
"××¡×™×‘×ª ×¤×•×¨×™× ×‘15 ×‘××¨×¥"

ğŸ’¡ **××¤×©×¨ ×’× ××¡×¤×¨ ××™×¨×•×¢×™×!**
"××¡×™×‘×ª ×¤×•×¨×™× ×‘15 ×‘××¨×¥ ×•×’× ××¡×™×‘×ª ×¡×™×•× ×‘30 ×‘×™×•× ×™"`,
        })
      } else if (
        userInput.includes('×”×•×“×¢×”') ||
        userInput.includes('×“×—×•×£') ||
        userInput === '2'
      ) {
        return NextResponse.json({
          success: true,
          message: `××¢×•×œ×”! ×‘×•× × ×™×¦×•×¨ ×”×•×“×¢×” ×“×—×•×¤×” ğŸ“¢

**×ª××¨ ××ª ×”×”×•×“×¢×”**, ×›×•×œ×œ:
â€¢ ×ª×•×›×Ÿ ×”×”×•×“×¢×” (×‘×¢×‘×¨×™×ª)
â€¢ ×ª××¨×™×š ×¡×™×•× - **×—×•×‘×”!** (×¢×“ ××ª×™ ×œ×”×¦×™×’)
â€¢ ×¡×•×’ ×”×”×•×“×¢×” (×“×—×•×£/××™×“×¢/××–×”×¨×”/×—×•×œ×¦×” ×œ×‘× ×”) - ××•×¤×¦×™×•× ×œ×™

**×“×•×’×××•×ª:**
"×ª×–×›×•×¨×ª ×—×•×œ×¦×” ×œ×‘× ×” ×œ××—×¨ ×¢×“ ×ª××¨×™×š 20/03/2025"

"××™×¨×•×¢ ×“×—×•×£: ×‘×™×˜×•×œ ×œ×™××•×“×™× ××—×¨ ×‘×’×œ×œ ××–×’ ××•×•×™×¨, ×¢×“ 18/03"

"×—×’ ×—× ×•×›×” ×©××—! ğŸ• ×ª×¨××” ×”×•×“×¢×” ×–×• ×œ××©×š 5 ×™××™×"

**ğŸ’¡ ×˜×™×¤:** ××¤×©×¨ ×œ×”×©×ª××© ×‘×ª××¨×™×›×™× ×™×—×¡×™×™×:
â€¢ "5 ×™××™×", "×©×‘×•×¢", "×¢×“ ×¡×•×£ ×”×—×•×“×©"`,
        })
      } else if (
        userInput.includes('×”×“×’×©×”') ||
        userInput.includes('×”×™×©×’') ||
        userInput.includes('×¤×¨×¡') ||
        userInput === '3'
      ) {
        return NextResponse.json({
          success: true,
          message: `××¢×•×œ×”! ×‘×•× × ×™×¦×•×¨ ×”×“×’×©×” ××™×•×—×“×ª âœ¨

**×ª××¨ ××ª ×”×”×“×’×©×”**, ×›×•×œ×œ:
â€¢ **× ×•×©× ×•×¡×•×’:** ×”×™×©×’/×¡×¤×•×¨×˜/×¤×¨×¡/××™×¨×•×¢/×”×•×“×¢×”
â€¢ **×›×•×ª×¨×ª ×§×¦×¨×”:** ××” ×§×¨×”? (×œ××©×œ: "××§×•× ×¨××©×•×Ÿ ×‘××œ×™×¤×•×ª")
â€¢ **×ª×™××•×¨ ××¤×•×¨×˜:** ×¤×¨×˜×™× × ×•×¡×¤×™× ×¢×œ ×”×”×™×©×’/××™×¨×•×¢
â€¢ **×ª××¨×™×š:** ××ª×™ ×–×” ×§×¨×”? (×× ×œ× ×ª×¦×™×™×Ÿ - ××©××œ!)
â€¢ **×§×˜×’×•×¨×™×”:** (×›×“×•×¨×¡×œ, ×©×—×™×™×”, ××× ×•×ª ×•×›×•' - ××•×˜×•××˜×™ ×× ×œ× ×ª×¦×™×™×Ÿ)

**×“×•×’×××•×ª:**
"×”×™×©×’ ×‘×›×“×•×¨×¡×œ - ×–×›×™× ×• ×‘××§×•× ×”×¨××©×•×Ÿ ×‘××œ×™×¤×•×ª ×”××—×•×– ×‘-15 ×‘××¨×¥ 2025"

"×¤×¨×¡ ×œ××•×¨×” ××¦×˜×™×™× ×ª - ×”×’×‘' ×¨×—×œ ×›×”×Ÿ ×–×›×ª×” ×‘×¤×¨×¡ ××¦×˜×™×™× ×•×ª ×—×™× ×•×›×™×ª"

"×”×™×©×’ ×‘×©×—×™×™×” - ×”×ª×œ××™×“ ×™×•×¡×™ ×œ×•×™ ×©×‘×¨ ×©×™× ×‘×™×ª ×”×¡×¤×¨ ×‘××©×š 100 ××˜×¨ ×—×•×¤×©×™ ×‘-20/03"

**ğŸ’¡ × ×™×ª×Ÿ ×’× ×œ×”×•×¡×™×£:**
â€¢ ×§×™×©×•×¨ ×œ××××¨/×ª××•× ×”
â€¢ ×ª××¨×™×›×™ ×ª×¦×•×’×” (×¢×“ ××ª×™ ×œ×”×¦×™×’ ×‘×§×¨×•×¡×œ×”)`,
        })
      } else {
        return NextResponse.json({
          success: true,
          message: '×œ× ×”×‘× ×ª×™ ××ª ×”×‘×—×™×¨×” ×©×œ×š ğŸ˜•\n\n×× × ×‘×—×¨:\n1ï¸âƒ£ ××™×¨×•×¢\n2ï¸âƒ£ ×”×•×“×¢×” ×“×—×•×¤×”\n3ï¸âƒ£ ×”×“×’×©×”',
        })
      }
    }

    // Handle understanding check for complex messages (Round 1)
    if (action === 'understand_message') {
      const response = await openai.chat.completions.create({
        model: AI_CONFIG.model,
        max_completion_tokens: AI_CONFIG.max_completion_tokens,
        messages: [
          { role: 'system', content: UNDERSTANDING_PROMPT },
          ...messages.map((msg) => ({
            role: msg.role,
            content: msg.content,
          })),
        ],
        // No function calling for understanding - just text response
      })

      const assistantMessage = response.choices[0].message

      // Log cost for analytics (Round 1)
      logAICost(
        response.usage,
        'understand_message',
        messages[messages.length - 1]?.content,
        1 // Round number
      )

      return NextResponse.json({
        success: true,
        message: assistantMessage.content || '×œ× ×”×‘× ×ª×™. ×× × × ×¡×” ×©×•×‘.',
        understanding: assistantMessage.content, // Save for context in next round
      })
    }

    // Handle data extraction with function calling
    if (action === 'extract_data') {
      // Use extraction prompt with optional context from understanding round
      const systemPrompt = getExtractionPrompt(context)

      console.log('[AI API] Extraction request:', {
        hasContext: !!context,
        contextPreview: context?.substring(0, 100),
        messageCount: messages.length,
        lastMessage: messages[messages.length - 1]?.content.substring(0, 100),
      })

      const response = await openai.chat.completions.create({
        model: AI_CONFIG.model,
        max_completion_tokens: AI_CONFIG.max_completion_tokens,
        // Note: temperature is not included - GPT-5 Mini only supports default value (1)
        messages: [
          { role: 'system', content: systemPrompt },
          ...messages.map((msg) => ({
            role: msg.role,
            content: msg.content,
          })),
        ],
        tools: AI_TOOLS,
        // Use 'auto' instead of 'required' to allow AI to ask for clarification if needed
        // The explicit instructions in the user message guide the AI to call functions
        tool_choice: 'auto',
      })

      const assistantMessage = response.choices[0].message

      // Log cost for analytics (Round 2 if context exists, Round 1 if simple message)
      const roundNumber = context ? 2 : 1
      logAICost(
        response.usage,
        'extract_data',
        messages[messages.length - 1]?.content,
        roundNumber
      )

      console.log('[AI API] GPT Response:', {
        hasToolCalls: !!assistantMessage.tool_calls,
        toolCallCount: assistantMessage.tool_calls?.length || 0,
        hasContent: !!assistantMessage.content,
        contentPreview: assistantMessage.content?.substring(0, 100),
        finishReason: response.choices[0].finish_reason,
      })

      // Check if AI wants to call a function
      if (assistantMessage.tool_calls && assistantMessage.tool_calls.length > 0) {
        const toolCall = assistantMessage.tool_calls[0]
        if (toolCall.type === 'function') {
          const functionName = toolCall.function.name
          const functionArgs = JSON.parse(toolCall.function.arguments)

          console.log('[AI Assistant] Function call detected:', {
            functionName,
            args: functionArgs,
          })

          // Validate and return extracted data
          if (functionName === 'create_events' && validateEventsArgs(functionArgs)) {
            return NextResponse.json({
              success: true,
              needsConfirmation: true,
              extractedData: {
                type: 'events',
                data: functionArgs.events,
              },
            })
          } else if (
          functionName === 'create_urgent_message' &&
          validateUrgentMessageArgs(functionArgs)
        ) {
          return NextResponse.json({
            success: true,
            needsConfirmation: true,
            extractedData: {
              type: 'urgent_message',
              data: functionArgs,
            },
          })
          } else if (
          functionName === 'create_highlight' &&
          validateHighlightArgs(functionArgs)
        ) {
          return NextResponse.json({
            success: true,
            needsConfirmation: true,
            extractedData: {
              type: 'highlight',
              data: functionArgs,
            },
          })
          } else {
            // Validation failed - return specific validation errors
            console.error('[AI Assistant] Validation failed:', {
              functionName,
              args: functionArgs,
              eventsValid: functionName === 'create_events' ? validateEventsArgs(functionArgs) : 'N/A',
              urgentValid: functionName === 'create_urgent_message' ? validateUrgentMessageArgs(functionArgs) : 'N/A',
            })

            // Generate specific validation error messages
            const validationErrors: string[] = []

            if (functionName === 'create_events') {
              if (!functionArgs.events || functionArgs.events.length === 0) {
                validationErrors.push('×œ× × ××¦××• ××™×¨×•×¢×™× ×œ×™×™×¦×•×¨')
              } else {
                functionArgs.events.forEach((event: any, index: number) => {
                  if (!event.title) validationErrors.push(`××™×¨×•×¢ ${index + 1}: ×—×¡×¨ ×©×`)
                  if (!event.start_datetime) validationErrors.push(`××™×¨×•×¢ ${index + 1}: ×—×¡×¨ ×ª××¨×™×š`)
                  if (!event.title_ru) validationErrors.push(`××™×¨×•×¢ ${index + 1}: ×—×¡×¨ ×ª×¨×’×•× ×¨×•×¡×™`)
                })
              }
            } else if (functionName === 'create_urgent_message') {
              if (!functionArgs.title_he) validationErrors.push('×—×¡×¨×” ×›×•×ª×¨×ª ×‘×¢×‘×¨×™×ª')
              if (!functionArgs.title_ru) validationErrors.push('×—×¡×¨ ×ª×¨×’×•× ×¨×•×¡×™')
              if (!functionArgs.end_date) validationErrors.push('×—×¡×¨ ×ª××¨×™×š ×¡×™×•×')
            } else if (functionName === 'create_highlight') {
              if (!functionArgs.type) validationErrors.push('×—×¡×¨ ×¡×•×’ ×”×“×’×©×”')
              if (!functionArgs.icon) validationErrors.push('×—×¡×¨ ××™×™×§×•×Ÿ')
              if (!functionArgs.title_he || functionArgs.title_he.length < 2) validationErrors.push('×›×•×ª×¨×ª ×‘×¢×‘×¨×™×ª ×—×™×™×‘×ª ×œ×”×›×™×œ ×œ×¤×—×•×ª 2 ×ª×•×•×™×')
              if (!functionArgs.description_he || functionArgs.description_he.length < 10) validationErrors.push('×ª×™××•×¨ ×‘×¢×‘×¨×™×ª ×—×™×™×‘ ×œ×”×›×™×œ ×œ×¤×—×•×ª 10 ×ª×•×•×™×')
              if (!functionArgs.category_he || functionArgs.category_he.length < 2) validationErrors.push('×§×˜×’×•×¨×™×” ×‘×¢×‘×¨×™×ª ×—×™×™×‘×ª ×œ×”×›×™×œ ×œ×¤×—×•×ª 2 ×ª×•×•×™×')
            }

            return NextResponse.json({
              success: false,
              error: '×©×’×™××” ×‘××™××•×ª ×”× ×ª×•× ×™× ×©×—×•×œ×¦×• ××”×”×•×“×¢×”',
              validationErrors,
            })
          }
        }
      }

      // AI responded with text (no function call) - this means it's asking for clarification
      // This is actually SUCCESS - AI is asking for missing information
      console.log('[AI Assistant] AI asking for clarification:', {
        content: assistantMessage.content,
        userMessage: messages[messages.length - 1]?.content,
        finishReason: response.choices[0].finish_reason,
      })

      return NextResponse.json({
        success: true,
        message: assistantMessage.content || '×œ× ×”×‘× ×ª×™. ×× × × ×¡×” ×©×•×‘.',
      })
    }

    return NextResponse.json({
      success: false,
      error: 'Invalid action',
    })
  } catch (error) {
    console.error('[AI Assistant] Error:', error)
    return NextResponse.json(
      {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
      },
      { status: 500 }
    )
  }
}
